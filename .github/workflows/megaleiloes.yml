name: ðŸŸ¢ MegaLeilÃµes - Scraper Completo
on:
  # ExecuÃ§Ã£o manual
  workflow_dispatch:
  
  # Cron automÃ¡tico - Todos os dias Ã s 3h UTC (0h BRT)
  schedule:
    - cron: '0 3 * * *'

jobs:
  scrape-megaleiloes:
    name: ðŸŸ¢ Scrape MegaLeilÃµes
    runs-on: ubuntu-latest
    timeout-minutes: 180
    
    steps:
      - name: ðŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ðŸ Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: ðŸ“¦ Instalar dependÃªncias
        run: |
          pip install --no-cache-dir \
            playwright==1.48.0 \
            beautifulsoup4==4.12.3 \
            requests==2.31.0
          playwright install chromium --with-deps
      
      - name: âœ… Verificar instalaÃ§Ã£o
        run: |
          python -c "from playwright.sync_api import sync_playwright; print('âœ… Playwright OK')"
          python -c "from bs4 import BeautifulSoup; print('âœ… BeautifulSoup OK')"
          python -c "import requests; print('âœ… Requests OK')"
      
      - name: ðŸŸ¢ Executar scraper MegaLeilÃµes
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "========================================"
          echo "ðŸŸ¢ MEGALEILÃ•ES - SCRAPER COMPLETO"
          echo "========================================"
          echo "ðŸ“… InÃ­cio: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "ðŸ‡§ðŸ‡· Brasil: $(TZ='America/Sao_Paulo' date '+%Y-%m-%d %H:%M:%S BRT')"
          echo "ðŸ“„ Modo: TODAS as pÃ¡ginas disponÃ­veis"
          echo "========================================"
          
          cd scrapers/megaleiloes
          python scraper.py
          
          echo ""
          echo "âœ… ConcluÃ­do: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
      
      - name: ðŸ’¾ Upload JSON (debug)
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: megaleiloes-data-${{ github.run_number }}
          path: scrapers/megaleiloes/data/megaleiloes_*.json
          retention-days: 3
      
      - name: ðŸ“Š Gerar resumo
        if: always()
        run: |
          echo "## ðŸŸ¢ MegaLeilÃµes - Resultado" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**HorÃ¡rio UTC:** $(date -u '+%Y-%m-%d %H:%M')" >> $GITHUB_STEP_SUMMARY
          echo "**HorÃ¡rio Brasil:** $(TZ='America/Sao_Paulo' date '+%Y-%m-%d %H:%M')" >> $GITHUB_STEP_SUMMARY
          echo "**Run #:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          
          if ls scrapers/megaleiloes/data/megaleiloes_*.json 1> /dev/null 2>&1; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ“Š Dados Coletados" >> $GITHUB_STEP_SUMMARY
            ITEM_COUNT=$(cat scrapers/megaleiloes/data/megaleiloes_*.json | grep -c '"external_id"' || echo "0")
            echo "- **Total de itens:** $ITEM_COUNT" >> $GITHUB_STEP_SUMMARY
          fi